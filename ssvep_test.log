nohup: ignoring input
[2025-11-28 13:08:26] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:08:56] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:09:26] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:09:56] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:10:26] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:10:56] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:11:26] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:11:56] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:12:26] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:12:56] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:13:26] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:13:56] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:14:26] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:14:56] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:15:26] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:15:56] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:16:26] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:16:56] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:17:26] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:17:56] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:18:26] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:18:56] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:19:26] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:19:56] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:20:26] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:20:56] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:21:26] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:21:56] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:22:26] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:22:56] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:23:26] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:23:56] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:24:26] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:24:56] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:25:26] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:25:56] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:26:26] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:26:56] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:27:26] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:27:56] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:28:26] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:28:56] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:29:26] PID 2442738 ä»åœ¨è¿è¡Œ...
[2025-11-28 13:30:00] INFO (torcheeg/MainThread) ğŸ” | Detected cached processing results, reading cache from ./cached_data/thubenchmark_EA.
[2025-11-28 13:30:04] INFO (torcheeg/MainThread) ğŸ“Š | Detected existing split of train and test set, use existing split from ./cached_data/thubenchmark_split/kfold_split.
[2025-11-28 13:30:04] INFO (torcheeg/MainThread) ğŸ’¡ | If the dataset is re-generated, you need to re-generate the split of the dataset instead of using the previous split.
[2025-11-28 13:30:04] INFO (torcheeg/MainThread) ğŸ“Š | Detected existing split of train and test set, use existing split from ./cached_data/thubenchmark_split/test_val_split_0.
[2025-11-28 13:30:04] INFO (torcheeg/MainThread) ğŸ’¡ | If the dataset is re-generated, you need to re-generate the split of the dataset instead of using the previous split.
/home/yhj/miniconda3/envs/torch/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
[2025-11-28 13:45:00] INFO (torcheeg/MainThread) ğŸ” | Detected cached processing results, reading cache from ./cached_data/thubenchmark_EA.
[2025-11-28 13:45:03] INFO (torcheeg/MainThread) ğŸ“Š | Detected existing split of train and test set, use existing split from ./cached_data/thubenchmark_split/kfold_split.
[2025-11-28 13:45:03] INFO (torcheeg/MainThread) ğŸ’¡ | If the dataset is re-generated, you need to re-generate the split of the dataset instead of using the previous split.
[2025-11-28 13:45:03] INFO (torcheeg/MainThread) ğŸ“Š | Detected existing split of train and test set, use existing split from ./cached_data/thubenchmark_split/test_val_split_0.
[2025-11-28 13:45:03] INFO (torcheeg/MainThread) ğŸ’¡ | If the dataset is re-generated, you need to re-generate the split of the dataset instead of using the previous split.
/home/yhj/miniconda3/envs/torch/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
[2025-11-28 14:00:00] INFO (torcheeg/MainThread) ğŸ” | Detected cached processing results, reading cache from ./cached_data/thubenchmark_EA.
[2025-11-28 14:00:04] INFO (torcheeg/MainThread) ğŸ“Š | Detected existing split of train and test set, use existing split from ./cached_data/thubenchmark_split/kfold_split.
[2025-11-28 14:00:04] INFO (torcheeg/MainThread) ğŸ’¡ | If the dataset is re-generated, you need to re-generate the split of the dataset instead of using the previous split.
[2025-11-28 14:00:04] INFO (torcheeg/MainThread) ğŸ“Š | Detected existing split of train and test set, use existing split from ./cached_data/thubenchmark_split/test_val_split_0.
[2025-11-28 14:00:04] INFO (torcheeg/MainThread) ğŸ’¡ | If the dataset is re-generated, you need to re-generate the split of the dataset instead of using the previous split.
/home/yhj/miniconda3/envs/torch/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
[2025-11-28 14:18:00] INFO (torcheeg/MainThread) ğŸ” | Detected cached processing results, reading cache from ./cached_data/thubenchmark_EA.
[2025-11-28 14:18:04] INFO (torcheeg/MainThread) ğŸ“Š | Detected existing split of train and test set, use existing split from ./cached_data/thubenchmark_split/kfold_split.
[2025-11-28 14:18:04] INFO (torcheeg/MainThread) ğŸ’¡ | If the dataset is re-generated, you need to re-generate the split of the dataset instead of using the previous split.
[2025-11-28 14:18:04] INFO (torcheeg/MainThread) ğŸ“Š | Detected existing split of train and test set, use existing split from ./cached_data/thubenchmark_split/test_val_split_0.
[2025-11-28 14:18:04] INFO (torcheeg/MainThread) ğŸ’¡ | If the dataset is re-generated, you need to re-generate the split of the dataset instead of using the previous split.
/home/yhj/miniconda3/envs/torch/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
